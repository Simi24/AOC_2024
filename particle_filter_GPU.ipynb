{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPquE/h9WO0LQQn1mm8bDop",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Simi24/AOC_2024/blob/main/particle_filter_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfFS1y_bEvuo",
        "outputId": "9aa4d20e-9999-4163-8964-bd20101f0e0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Oct  6 21:10:25 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile particle_filter_config.h\n",
        "\n",
        "// particle_filter_config.h\n",
        "// Configuration and data structures for the particle filter\n",
        "\n",
        "#ifndef PARTICLE_FILTER_CONFIG_H\n",
        "#define PARTICLE_FILTER_CONFIG_H\n",
        "\n",
        "#include <cuda_runtime.h>\n",
        "#include <curand_kernel.h>\n",
        "\n",
        "/* =================================================== */\n",
        "/* SIMULATION PARAMETERS                               */\n",
        "/* =================================================== */\n",
        "#define N_PARTICLES      100000000\n",
        "#define N_TIMESTEPS      100\n",
        "#define DT               0.1f\n",
        "#define PROCESS_NOISE    0.3f\n",
        "#define MEASUREMENT_NOISE 1.0f\n",
        "#define INIT_NOISE       0.5f\n",
        "\n",
        "/* =================================================== */\n",
        "/* CONSTANT MEMORY DECLARATIONS                        */\n",
        "/* =================================================== */\n",
        "__constant__ float c_dt = DT;\n",
        "__constant__ float c_process_noise = PROCESS_NOISE;\n",
        "__constant__ float c_measurement_noise = MEASUREMENT_NOISE;\n",
        "__constant__ int c_n_particles = N_PARTICLES;\n",
        "\n",
        "/* =================================================== */\n",
        "/* TEXTURE MEMORY DECLARATIONS                         */\n",
        "/* =================================================== */\n",
        "// Texture objects are now managed per-particle-filter instance\n",
        "\n",
        "/* =================================================== */\n",
        "/* CUDA OPTIMIZATION PARAMETERS                        */\n",
        "/* =================================================== */\n",
        "// Optimal thread count for modern GPUs (multiple of 32 for warp alignment)\n",
        "#define THREADS_PER_BLOCK 256\n",
        "#define WARP_SIZE        32\n",
        "\n",
        "// Number of warps per block\n",
        "#define WARPS_PER_BLOCK  (THREADS_PER_BLOCK / WARP_SIZE)\n",
        "\n",
        "// For reduction kernels - must be power of 2\n",
        "#define REDUCTION_THREADS 256\n",
        "\n",
        "// Number of CUDA streams for concurrent execution\n",
        "#define NUM_STREAMS      4\n",
        "\n",
        "// Macro to compute grid size\n",
        "#define GRID_SIZE(n, block_size) (((n) + (block_size) - 1) / (block_size))\n",
        "\n",
        "/* =================================================== */\n",
        "/* ERROR CHECKING MACRO                                */\n",
        "/* =================================================== */\n",
        "#define CUDA_CHECK(call) { \\\n",
        "    const cudaError_t error = call; \\\n",
        "    if (error != cudaSuccess) { \\\n",
        "        fprintf(stderr, \"CUDA Error: %s:%d, \", __FILE__, __LINE__); \\\n",
        "        fprintf(stderr, \"code: %d, reason: %s\\n\", error, \\\n",
        "                cudaGetErrorString(error)); \\\n",
        "        exit(EXIT_FAILURE); \\\n",
        "    } \\\n",
        "}\n",
        "\n",
        "/* =================================================== */\n",
        "/* DATA STRUCTURES                                     */\n",
        "/* =================================================== */\n",
        "\n",
        "// Particle structure - aligned for coalesced memory access\n",
        "typedef struct __align__(16) {\n",
        "    float x;   // Position x\n",
        "    float y;   // Position y\n",
        "    float vx;  // Velocity x\n",
        "    float vy;  // Velocity y\n",
        "} Particle;\n",
        "\n",
        "// Structure for tracking results\n",
        "typedef struct {\n",
        "    float time;\n",
        "    float true_x, true_y;\n",
        "    float obs_x, obs_y;\n",
        "    float est_x, est_y;\n",
        "    float error;\n",
        "} Result;\n",
        "\n",
        "/* =================================================== */\n",
        "/* INLINE DEVICE FUNCTIONS                             */\n",
        "/* =================================================== */\n",
        "\n",
        "// Fast square function\n",
        "__device__ __forceinline__ float square(float x) {\n",
        "    return x * x;\n",
        "}\n",
        "\n",
        "// Warp-level reduction using shuffle instructions (no shared memory)\n",
        "__device__ __forceinline__ float warp_reduce_sum(float val) {\n",
        "    #pragma unroll\n",
        "    for (int offset = WARP_SIZE / 2; offset > 0; offset >>= 1) {\n",
        "        val += __shfl_down_sync(0xffffffff, val, offset);\n",
        "    }\n",
        "    return val;\n",
        "}\n",
        "\n",
        "#endif // PARTICLE_FILTER_CONFIG_H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq2qjWmXE5re",
        "outputId": "fe59cc68-2c4c-4ff5-c594-14801521eb76"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting particle_filter_config.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile scan_kernels.cu\n",
        "// scan_kernels.cu\n",
        "// Optimized implementation of parallel prefix sum (scan) to replace Thrust\n",
        "// Uses Blelloch scan algorithm with work-efficient approach\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include \"particle_filter_config.h\"\n",
        "\n",
        "/* =================================================== */\n",
        "/* INCLUSIVE SCAN (PREFIX SUM) IMPLEMENTATION          */\n",
        "/* =================================================== */\n",
        "\n",
        "/**\n",
        " * Simple inclusive scan using shared memory - more reliable implementation\n",
        " * Based on the classic reduction pattern\n",
        " */\n",
        "__device__ void block_inclusive_scan_simple(float* sdata, int tid, int n) {\n",
        "    // First, copy to shared memory if needed (assume already done)\n",
        "    __syncthreads();\n",
        "\n",
        "    // Perform inclusive scan\n",
        "    for (int stride = 1; stride < n; stride *= 2) {\n",
        "        __syncthreads();\n",
        "        if (tid >= stride && tid < n) {\n",
        "            sdata[tid] += sdata[tid - stride];\n",
        "        }\n",
        "    }\n",
        "    __syncthreads();\n",
        "}\n",
        "\n",
        "/**\n",
        " * Kernel 1: Performs scan on blocks and outputs block sums\n",
        " * Each block processes THREADS_PER_BLOCK * 2 elements\n",
        " */\n",
        "__global__ void scan_blocks_kernel(\n",
        "    const float* __restrict__ input,\n",
        "    float* __restrict__ output,\n",
        "    float* __restrict__ block_sums,\n",
        "    int n\n",
        ") {\n",
        "    __shared__ float temp[THREADS_PER_BLOCK * 2];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    int block_offset = blockIdx.x * THREADS_PER_BLOCK * 2;\n",
        "\n",
        "    // Load data into shared memory with bounds checking\n",
        "    int idx1 = block_offset + tid;\n",
        "    int idx2 = block_offset + tid + THREADS_PER_BLOCK;\n",
        "\n",
        "    temp[tid] = (idx1 < n) ? input[idx1] : 0.0f;\n",
        "    temp[tid + THREADS_PER_BLOCK] = (idx2 < n) ? input[idx2] : 0.0f;\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // Determine actual number of elements to scan in this block\n",
        "    int elements_in_block = min(THREADS_PER_BLOCK * 2, n - block_offset);\n",
        "    if (elements_in_block <= 0) return;\n",
        "\n",
        "    // Perform block-level inclusive scan\n",
        "    block_inclusive_scan_simple(temp, tid, elements_in_block);\n",
        "\n",
        "    // Write results back to global memory with bounds checking\n",
        "    if (idx1 < n) output[idx1] = temp[tid];\n",
        "    if (idx2 < n) output[idx2] = temp[tid + THREADS_PER_BLOCK];\n",
        "\n",
        "    // Last thread in block writes the block sum\n",
        "    if (tid == 0 && block_sums != NULL) {\n",
        "        int last_idx = min(THREADS_PER_BLOCK * 2 - 1, elements_in_block - 1);\n",
        "        if (last_idx >= 0) {\n",
        "            block_sums[blockIdx.x] = temp[last_idx];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "/**\n",
        " * Kernel 2: Adds scanned block sums to each block's elements\n",
        " * Avoids warp divergence by having all threads in a block work together\n",
        " */\n",
        "__global__ void add_block_sums_kernel(\n",
        "    float* __restrict__ data,\n",
        "    const float* __restrict__ block_sums,\n",
        "    int n\n",
        ") {\n",
        "    int tid = threadIdx.x;\n",
        "    int block_offset = blockIdx.x * THREADS_PER_BLOCK * 2;\n",
        "\n",
        "    // Check if this block has any valid elements\n",
        "    if (block_offset >= n) return;\n",
        "\n",
        "    // Load the cumulative sum from previous blocks\n",
        "    float block_sum = (blockIdx.x > 0) ? block_sums[blockIdx.x - 1] : 0.0f;\n",
        "\n",
        "    // Add to both elements this thread is responsible for\n",
        "    int idx1 = block_offset + tid;\n",
        "    int idx2 = block_offset + tid + THREADS_PER_BLOCK;\n",
        "\n",
        "    if (idx1 < n) data[idx1] += block_sum;\n",
        "    if (idx2 < n) data[idx2] += block_sum;\n",
        "}\n",
        "\n",
        "/**\n",
        " * Host function: Performs inclusive scan on device array\n",
        " * Replaces thrust::inclusive_scan\n",
        " *\n",
        " * @param d_input: Device input array\n",
        " * @param d_output: Device output array\n",
        " * @param n: Number of elements\n",
        " * @param stream: CUDA stream for async execution\n",
        " */\n",
        "void inclusive_scan(\n",
        "    const float* d_input,\n",
        "    float* d_output,\n",
        "    int n,\n",
        "    cudaStream_t stream = 0\n",
        ") {\n",
        "    if (n <= 0) return;\n",
        "\n",
        "    // Calculate grid dimensions\n",
        "    int elements_per_block = THREADS_PER_BLOCK * 2;\n",
        "    int num_blocks = GRID_SIZE(n, elements_per_block);\n",
        "\n",
        "    if (num_blocks == 1) {\n",
        "        // Single block - no need for second pass\n",
        "        scan_blocks_kernel<<<1, THREADS_PER_BLOCK, 0, stream>>>(\n",
        "            d_input, d_output, NULL, n\n",
        "        );\n",
        "        CUDA_CHECK(cudaStreamSynchronize(stream));\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    // Allocate temporary storage for block sums\n",
        "    float* d_block_sums;\n",
        "    CUDA_CHECK(cudaMalloc(&d_block_sums, num_blocks * sizeof(float)));\n",
        "\n",
        "    // Phase 1: Scan each block\n",
        "    scan_blocks_kernel<<<num_blocks, THREADS_PER_BLOCK, 0, stream>>>(\n",
        "        d_input, d_output, d_block_sums, n\n",
        "    );\n",
        "    CUDA_CHECK(cudaStreamSynchronize(stream));\n",
        "\n",
        "    // Phase 2: Scan the block sums recursively if needed\n",
        "    if (num_blocks > 1) {\n",
        "        float* d_scanned_block_sums;\n",
        "        CUDA_CHECK(cudaMalloc(&d_scanned_block_sums, num_blocks * sizeof(float)));\n",
        "\n",
        "        // Recursively scan block sums\n",
        "        inclusive_scan(d_block_sums, d_scanned_block_sums, num_blocks, stream);\n",
        "\n",
        "        // Phase 3: Add scanned block sums to all blocks\n",
        "        add_block_sums_kernel<<<num_blocks, THREADS_PER_BLOCK, 0, stream>>>(\n",
        "            d_output, d_scanned_block_sums, n\n",
        "        );\n",
        "        CUDA_CHECK(cudaStreamSynchronize(stream));\n",
        "\n",
        "        CUDA_CHECK(cudaFree(d_scanned_block_sums));\n",
        "    }\n",
        "\n",
        "    CUDA_CHECK(cudaFree(d_block_sums));\n",
        "}\n",
        "\n",
        "/**\n",
        " * In-place version of inclusive scan\n",
        " */\n",
        "void inclusive_scan_inplace(float* d_data, int n, cudaStream_t stream = 0) {\n",
        "    inclusive_scan(d_data, d_data, n, stream);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWik9cuKLKzA",
        "outputId": "09aa0f6c-05a8-4cdf-cd02-bcf4de633297"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting scan_kernels.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile reduce_kernels.cu\n",
        "// reduce_kernels.cu\n",
        "// Optimized reduction kernels to replace Thrust reduce operations\n",
        "// Uses warp shuffle, shared memory, and unwrapping for maximum performance\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include \"particle_filter_config.h\"\n",
        "\n",
        "/* =================================================== */\n",
        "/* REDUCTION KERNELS                                   */\n",
        "/* =================================================== */\n",
        "\n",
        "/**\n",
        " * Optimized reduction kernel using:\n",
        " * - Warp shuffle instructions for final warp reduction (no shared mem needed)\n",
        " * - Sequential addressing to avoid bank conflicts\n",
        " * - Loop unrolling for better instruction-level parallelism\n",
        " * - Each thread processes multiple elements to reduce kernel launches\n",
        " *\n",
        " * Template allows for different operations (sum, max, etc.)\n",
        " */\n",
        "template<typename T, typename Op>\n",
        "__global__ void reduce_kernel(\n",
        "    const T* __restrict__ input,\n",
        "    T* __restrict__ output,\n",
        "    int n,\n",
        "    T identity\n",
        ") {\n",
        "    extern __shared__ T sdata[];\n",
        "\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = blockIdx.x * (blockDim.x * 2) + threadIdx.x;\n",
        "    unsigned int grid_size = blockDim.x * 2 * gridDim.x;\n",
        "\n",
        "    T sum = identity;\n",
        "\n",
        "    // Grid-stride loop: each thread accumulates multiple elements\n",
        "    // This reduces the number of blocks needed\n",
        "    while (i < n) {\n",
        "        sum = Op()(sum, input[i]);\n",
        "        if (i + blockDim.x < n) {\n",
        "            sum = Op()(sum, input[i + blockDim.x]);\n",
        "        }\n",
        "        i += grid_size;\n",
        "    }\n",
        "\n",
        "    sdata[tid] = sum;\n",
        "    __syncthreads();\n",
        "\n",
        "    // Reduction in shared memory with sequential addressing\n",
        "    // Unrolled for blocks of 256 threads\n",
        "    if (blockDim.x >= 512) {\n",
        "        if (tid < 256) { sdata[tid] = Op()(sdata[tid], sdata[tid + 256]); }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (blockDim.x >= 256) {\n",
        "        if (tid < 128) { sdata[tid] = Op()(sdata[tid], sdata[tid + 128]); }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (blockDim.x >= 128) {\n",
        "        if (tid < 64) { sdata[tid] = Op()(sdata[tid], sdata[tid + 64]); }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Final warp reduction using shuffle instructions (no __syncthreads needed)\n",
        "    if (tid < 32) {\n",
        "        volatile T* smem = sdata;\n",
        "        if (blockDim.x >= 64) smem[tid] = Op()(smem[tid], smem[tid + 32]);\n",
        "\n",
        "        // Last warp uses shuffle instructions - much faster than shared memory\n",
        "        T val = smem[tid];\n",
        "        #pragma unroll\n",
        "        for (int offset = 16; offset > 0; offset >>= 1) {\n",
        "            T other = __shfl_down_sync(0xffffffff, val, offset);\n",
        "            val = Op()(val, other);\n",
        "        }\n",
        "\n",
        "        if (tid == 0) output[blockIdx.x] = val;\n",
        "    }\n",
        "}\n",
        "\n",
        "/* =================================================== */\n",
        "/* OPERATION FUNCTORS                                  */\n",
        "/* =================================================== */\n",
        "\n",
        "// Functor for sum operation\n",
        "struct SumOp {\n",
        "    __device__ __forceinline__ float operator()(float a, float b) const {\n",
        "        return a + b;\n",
        "    }\n",
        "};\n",
        "\n",
        "// Functor for sum of squares operation (for ESS calculation)\n",
        "struct SumSquaresOp {\n",
        "    __device__ __forceinline__ float operator()(float a, float b) const {\n",
        "        return a + b * b;\n",
        "    }\n",
        "};\n",
        "\n",
        "/* =================================================== */\n",
        "/* HOST INTERFACE FUNCTIONS                            */\n",
        "/* =================================================== */\n",
        "\n",
        "/**\n",
        " * Performs sum reduction on device array\n",
        " * Replaces thrust::reduce\n",
        " *\n",
        " * @param d_input: Device input array\n",
        " * @param n: Number of elements\n",
        " * @param stream: CUDA stream for async execution\n",
        " * @return: Sum of all elements\n",
        " */\n",
        "float reduce_sum(const float* d_input, int n, cudaStream_t stream = 0) {\n",
        "    // Calculate optimal grid size\n",
        "    // Use fewer blocks but more work per thread for better efficiency\n",
        "    int threads = REDUCTION_THREADS;\n",
        "    int blocks = min(256, GRID_SIZE(n, threads * 2));\n",
        "\n",
        "    // Allocate temporary storage for block results\n",
        "    float* d_block_results;\n",
        "    CUDA_CHECK(cudaMalloc(&d_block_results, blocks * sizeof(float)));\n",
        "\n",
        "    // First reduction\n",
        "    reduce_kernel<float, SumOp><<<blocks, threads, threads * sizeof(float), stream>>>(\n",
        "        d_input, d_block_results, n, 0.0f\n",
        "    );\n",
        "\n",
        "    float result;\n",
        "    if (blocks == 1) {\n",
        "        // Single block - copy result directly\n",
        "        CUDA_CHECK(cudaMemcpyAsync(&result, d_block_results, sizeof(float),\n",
        "                                   cudaMemcpyDeviceToHost, stream));\n",
        "        CUDA_CHECK(cudaStreamSynchronize(stream));\n",
        "    } else {\n",
        "        // Multiple blocks - need second reduction\n",
        "        float* d_final_result;\n",
        "        CUDA_CHECK(cudaMalloc(&d_final_result, sizeof(float)));\n",
        "\n",
        "        reduce_kernel<float, SumOp><<<1, threads, threads * sizeof(float), stream>>>(\n",
        "            d_block_results, d_final_result, blocks, 0.0f\n",
        "        );\n",
        "\n",
        "        CUDA_CHECK(cudaMemcpyAsync(&result, d_final_result, sizeof(float),\n",
        "                                   cudaMemcpyDeviceToHost, stream));\n",
        "        CUDA_CHECK(cudaStreamSynchronize(stream));\n",
        "        CUDA_CHECK(cudaFree(d_final_result));\n",
        "    }\n",
        "\n",
        "    CUDA_CHECK(cudaFree(d_block_results));\n",
        "    return result;\n",
        "}\n",
        "\n",
        "/**\n",
        " * Performs sum of squares reduction\n",
        " * Used for ESS (Effective Sample Size) calculation\n",
        " * Replaces thrust::transform_reduce with square operation\n",
        " *\n",
        " * @param d_input: Device input array\n",
        " * @param n: Number of elements\n",
        " * @param stream: CUDA stream for async execution\n",
        " * @return: Sum of squares of all elements\n",
        " */\n",
        "float reduce_sum_squares(const float* d_input, int n, cudaStream_t stream = 0) {\n",
        "    int threads = REDUCTION_THREADS;\n",
        "    int blocks = min(256, GRID_SIZE(n, threads * 2));\n",
        "\n",
        "    float* d_block_results;\n",
        "    CUDA_CHECK(cudaMalloc(&d_block_results, blocks * sizeof(float)));\n",
        "\n",
        "    reduce_kernel<float, SumSquaresOp><<<blocks, threads, threads * sizeof(float), stream>>>(\n",
        "        d_input, d_block_results, n, 0.0f\n",
        "    );\n",
        "\n",
        "    float result;\n",
        "    if (blocks == 1) {\n",
        "        CUDA_CHECK(cudaMemcpyAsync(&result, d_block_results, sizeof(float),\n",
        "                                   cudaMemcpyDeviceToHost, stream));\n",
        "        CUDA_CHECK(cudaStreamSynchronize(stream));\n",
        "    } else {\n",
        "        float* d_final_result;\n",
        "        CUDA_CHECK(cudaMalloc(&d_final_result, sizeof(float)));\n",
        "\n",
        "        reduce_kernel<float, SumOp><<<1, threads, threads * sizeof(float), stream>>>(\n",
        "            d_block_results, d_final_result, blocks, 0.0f\n",
        "        );\n",
        "\n",
        "        CUDA_CHECK(cudaMemcpyAsync(&result, d_final_result, sizeof(float),\n",
        "                                   cudaMemcpyDeviceToHost, stream));\n",
        "        CUDA_CHECK(cudaStreamSynchronize(stream));\n",
        "        CUDA_CHECK(cudaFree(d_final_result));\n",
        "    }\n",
        "\n",
        "    CUDA_CHECK(cudaFree(d_block_results));\n",
        "    return result;\n",
        "}\n",
        "\n",
        "/* =================================================== */\n",
        "/* WEIGHTED REDUCTION FOR STATE ESTIMATION             */\n",
        "/* =================================================== */\n",
        "\n",
        "/**\n",
        " * Optimized kernel for computing weighted average in a single pass\n",
        " * Reduces memory bandwidth requirements\n",
        " */\n",
        "__global__ void weighted_reduce_kernel(\n",
        "    const Particle* __restrict__ particles,\n",
        "    const float* __restrict__ weights,\n",
        "    int n,\n",
        "    float* __restrict__ out_x,\n",
        "    float* __restrict__ out_y\n",
        ") {\n",
        "    __shared__ float sdata_x[REDUCTION_THREADS];\n",
        "    __shared__ float sdata_y[REDUCTION_THREADS];\n",
        "\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = blockIdx.x * (blockDim.x * 2) + threadIdx.x;\n",
        "    unsigned int grid_size = blockDim.x * 2 * gridDim.x;\n",
        "\n",
        "    float sum_x = 0.0f;\n",
        "    float sum_y = 0.0f;\n",
        "\n",
        "    // Grid-stride loop for coalesced memory access\n",
        "    while (i < n) {\n",
        "        float w = weights[i];\n",
        "        sum_x += particles[i].x * w;\n",
        "        sum_y += particles[i].y * w;\n",
        "\n",
        "        if (i + blockDim.x < n) {\n",
        "            float w2 = weights[i + blockDim.x];\n",
        "            sum_x += particles[i + blockDim.x].x * w2;\n",
        "            sum_y += particles[i + blockDim.x].y * w2;\n",
        "        }\n",
        "        i += grid_size;\n",
        "    }\n",
        "\n",
        "    sdata_x[tid] = sum_x;\n",
        "    sdata_y[tid] = sum_y;\n",
        "    __syncthreads();\n",
        "\n",
        "    // Reduction with unrolling\n",
        "    if (blockDim.x >= 512) {\n",
        "        if (tid < 256) {\n",
        "            sdata_x[tid] += sdata_x[tid + 256];\n",
        "            sdata_y[tid] += sdata_y[tid + 256];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (blockDim.x >= 256) {\n",
        "        if (tid < 128) {\n",
        "            sdata_x[tid] += sdata_x[tid + 128];\n",
        "            sdata_y[tid] += sdata_y[tid + 128];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (blockDim.x >= 128) {\n",
        "        if (tid < 64) {\n",
        "            sdata_x[tid] += sdata_x[tid + 64];\n",
        "            sdata_y[tid] += sdata_y[tid + 64];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Final warp reduction\n",
        "    if (tid < 32) {\n",
        "        volatile float* smem_x = sdata_x;\n",
        "        volatile float* smem_y = sdata_y;\n",
        "        if (blockDim.x >= 64) {\n",
        "            smem_x[tid] += smem_x[tid + 32];\n",
        "            smem_y[tid] += smem_y[tid + 32];\n",
        "        }\n",
        "\n",
        "        float val_x = smem_x[tid];\n",
        "        float val_y = smem_y[tid];\n",
        "        #pragma unroll\n",
        "        for (int offset = 16; offset > 0; offset >>= 1) {\n",
        "            val_x += __shfl_down_sync(0xffffffff, val_x, offset);\n",
        "            val_y += __shfl_down_sync(0xffffffff, val_y, offset);\n",
        "        }\n",
        "\n",
        "        if (tid == 0) {\n",
        "            out_x[blockIdx.x] = val_x;\n",
        "            out_y[blockIdx.x] = val_y;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "/**\n",
        " * Computes weighted average of particle positions\n",
        " * Returns result through output parameters\n",
        " */\n",
        "void weighted_average(\n",
        "    const Particle* d_particles,\n",
        "    const float* d_weights,\n",
        "    int n,\n",
        "    float* est_x,\n",
        "    float* est_y,\n",
        "    cudaStream_t stream = 0\n",
        ") {\n",
        "    int threads = REDUCTION_THREADS;\n",
        "    int blocks = min(256, GRID_SIZE(n, threads * 2));\n",
        "\n",
        "    float *d_block_x, *d_block_y;\n",
        "    CUDA_CHECK(cudaMalloc(&d_block_x, blocks * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_block_y, blocks * sizeof(float)));\n",
        "\n",
        "    weighted_reduce_kernel<<<blocks, threads, 0, stream>>>(\n",
        "        d_particles, d_weights, n, d_block_x, d_block_y\n",
        "    );\n",
        "\n",
        "    if (blocks == 1) {\n",
        "        CUDA_CHECK(cudaMemcpyAsync(est_x, d_block_x, sizeof(float),\n",
        "                                   cudaMemcpyDeviceToHost, stream));\n",
        "        CUDA_CHECK(cudaMemcpyAsync(est_y, d_block_y, sizeof(float),\n",
        "                                   cudaMemcpyDeviceToHost, stream));\n",
        "        CUDA_CHECK(cudaStreamSynchronize(stream));\n",
        "    } else {\n",
        "        // Perform final reduction on the block results\n",
        "        float *d_final_x, *d_final_y;\n",
        "        CUDA_CHECK(cudaMalloc(&d_final_x, sizeof(float)));\n",
        "        CUDA_CHECK(cudaMalloc(&d_final_y, sizeof(float)));\n",
        "\n",
        "        // Final reduction for x\n",
        "        reduce_kernel<float, SumOp><<<1, threads, threads * sizeof(float), stream>>>(\n",
        "            d_block_x, d_final_x, blocks, 0.0f\n",
        "        );\n",
        "\n",
        "        // Final reduction for y\n",
        "        reduce_kernel<float, SumOp><<<1, threads, threads * sizeof(float), stream>>>(\n",
        "            d_block_y, d_final_y, blocks, 0.0f\n",
        "        );\n",
        "\n",
        "        // Copy results back to host\n",
        "        CUDA_CHECK(cudaMemcpyAsync(est_x, d_final_x, sizeof(float),\n",
        "                                   cudaMemcpyDeviceToHost, stream));\n",
        "        CUDA_CHECK(cudaMemcpyAsync(est_y, d_final_y, sizeof(float),\n",
        "                                   cudaMemcpyDeviceToHost, stream));\n",
        "        CUDA_CHECK(cudaStreamSynchronize(stream));\n",
        "\n",
        "        CUDA_CHECK(cudaFree(d_final_x));\n",
        "        CUDA_CHECK(cudaFree(d_final_y));\n",
        "    }\n",
        "\n",
        "    CUDA_CHECK(cudaFree(d_block_x));\n",
        "    CUDA_CHECK(cudaFree(d_block_y));\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5BMx82xLSnk",
        "outputId": "f81cb93d-4a38-4066-987b-7e92bc762c7d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting reduce_kernels.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile particle_filter_kernels.cu\n",
        "// particle_filter_kernels.cu\n",
        "// Core particle filter CUDA kernels with full optimizations\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include \"particle_filter_config.h\"\n",
        "\n",
        "/* =================================================== */\n",
        "/* TRAJECTORY GENERATION                               */\n",
        "/* =================================================== */\n",
        "\n",
        "/**\n",
        " * Generates true trajectory (ground truth)\n",
        " * Piecewise motion model for realistic tracking scenario\n",
        " */\n",
        "__host__ __device__ void generate_trajectory(\n",
        "    float t,\n",
        "    float* x,\n",
        "    float* y\n",
        ") {\n",
        "    const float speed = 3.0f;\n",
        "\n",
        "    if (t < 2.0f) {\n",
        "        // Straight line motion\n",
        "        *x = 0.0f + speed * t;\n",
        "        *y = 0.0f;\n",
        "    } else if (t < 4.0f) {\n",
        "        // Accelerating turn\n",
        "        float t_local = t - 2.0f;\n",
        "        *x = 6.0f + speed * t_local;\n",
        "        *y = 0.5f * t_local * t_local;\n",
        "    } else if (t < 6.0f) {\n",
        "        // Diagonal motion\n",
        "        float t_local = t - 4.0f;\n",
        "        *x = 12.0f + speed * 0.7f * t_local;\n",
        "        *y = 2.0f + speed * 0.7f * t_local;\n",
        "    } else if (t < 8.0f) {\n",
        "        // Descending turn\n",
        "        float t_local = t - 6.0f;\n",
        "        *x = 16.2f + speed * 0.5f * t_local;\n",
        "        *y = 10.8f - speed * 0.8f * t_local;\n",
        "    } else {\n",
        "        // Final straight segment\n",
        "        float t_local = t - 8.0f;\n",
        "        *x = 19.2f + speed * t_local;\n",
        "        *y = 4.4f + speed * 0.2f * t_local;\n",
        "    }\n",
        "}\n",
        "\n",
        "extern \"C\" {\n",
        "\n",
        "/* =================================================== */\n",
        "/* PARTICLE INITIALIZATION                             */\n",
        "/* =================================================== */\n",
        "\n",
        "/**\n",
        " * Initializes particles with random perturbations around initial state\n",
        " * Optimized for:\n",
        " * - Coalesced memory access (threads access consecutive particles)\n",
        " * - Efficient random number generation (cuRAND)\n",
        " *\n",
        " * @param particles: Output particle array\n",
        " * @param rand_states: cuRAND state for each particle\n",
        " * @param n: Number of particles\n",
        " * @param init_x, init_y: Initial position\n",
        " */\n",
        "__global__ void init_particles_kernel(\n",
        "    Particle* __restrict__ particles,\n",
        "    curandState* __restrict__ rand_states,\n",
        "    int n,\n",
        "    float init_x,\n",
        "    float init_y\n",
        ") {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Guard against out-of-bounds access\n",
        "    if (idx >= n) return;\n",
        "\n",
        "    // Initialize random state for this particle first\n",
        "    curand_init(1234ULL + idx, 0, 0, &rand_states[idx]);\n",
        "\n",
        "    // Initialize particle with small random noise around initial position\n",
        "    float noise_x = curand_normal(&rand_states[idx]) * INIT_NOISE;\n",
        "    float noise_y = curand_normal(&rand_states[idx]) * INIT_NOISE;\n",
        "    float noise_vx = curand_normal(&rand_states[idx]) * 0.1f;  // Small velocity noise\n",
        "    float noise_vy = curand_normal(&rand_states[idx]) * 0.1f;\n",
        "\n",
        "    particles[idx].x = init_x + noise_x;\n",
        "    particles[idx].y = init_y + noise_y;\n",
        "    particles[idx].vx = 3.0f + noise_vx;  // Initial velocity around 3.0\n",
        "    particles[idx].vy = 0.0f + noise_vy;  // Initial vy around 0.0\n",
        "}\n",
        "\n",
        "/* =================================================== */\n",
        "/* PREDICTION STEP                                     */\n",
        "/* =================================================== */\n",
        "\n",
        "/**\n",
        " * Predicts particle states forward in time using motion model\n",
        " * Optimized for:\n",
        " * - Coalesced memory access\n",
        " * - Minimal register usage\n",
        " * - No warp divergence (all threads execute same path)\n",
        " *\n",
        " * @param particles: Input/output particle array\n",
        " * @param rand_states: Random number generator states\n",
        " * @param n: Number of particles\n",
        " * @param dt: Time step\n",
        " * @param process_noise: Process noise standard deviation\n",
        " */\n",
        "__global__ void predict_kernel(\n",
        "    Particle* __restrict__ particles,\n",
        "    curandState* __restrict__ rand_states,\n",
        "    int n\n",
        ") {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (idx >= n) return;\n",
        "\n",
        "    // Load random state to local memory for efficiency\n",
        "    curandState local_state = rand_states[idx];\n",
        "\n",
        "    // Load particle to registers\n",
        "    Particle p = particles[idx];\n",
        "\n",
        "    // Constant velocity model with Gaussian noise (using constant memory)\n",
        "    float noise_scale = c_process_noise * c_dt;\n",
        "    p.x += p.vx * c_dt + curand_normal(&local_state) * noise_scale;\n",
        "    p.y += p.vy * c_dt + curand_normal(&local_state) * noise_scale;\n",
        "\n",
        "    // Velocity random walk\n",
        "    float vel_noise_scale = c_process_noise * 0.2f * c_dt;\n",
        "    p.vx += curand_normal(&local_state) * vel_noise_scale;\n",
        "    p.vy += curand_normal(&local_state) * vel_noise_scale;\n",
        "\n",
        "    // Write back to global memory\n",
        "    particles[idx] = p;\n",
        "    rand_states[idx] = local_state;\n",
        "}\n",
        "\n",
        "/* =================================================== */\n",
        "/* UPDATE WEIGHTS (MEASUREMENT UPDATE)                 */\n",
        "/* =================================================== */\n",
        "\n",
        "/**\n",
        " * Updates particle weights based on observation likelihood\n",
        " * Optimized for:\n",
        " * - Coalesced reads/writes\n",
        " * - Fast math operations (no divergence)\n",
        " * - Minimal memory transactions\n",
        " *\n",
        " * @param particles: Input particle array\n",
        " * @param weights: Output weights array\n",
        " * @param n: Number of particles\n",
        " * @param obs_x, obs_y: Observed position\n",
        " * @param measurement_noise: Measurement noise standard deviation\n",
        " */\n",
        "__global__ void update_weights_kernel(\n",
        "    const Particle* __restrict__ particles,\n",
        "    float* __restrict__ weights,\n",
        "    int n,\n",
        "    float obs_x,\n",
        "    float obs_y\n",
        ") {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (idx >= n) return;\n",
        "\n",
        "    // Load particle position to registers\n",
        "    float px = particles[idx].x;\n",
        "    float py = particles[idx].y;\n",
        "\n",
        "    // Compute squared distance to observation\n",
        "    float dx = px - obs_x;\n",
        "    float dy = py - obs_y;\n",
        "    float dist_sq = dx * dx + dy * dy;\n",
        "\n",
        "    // Gaussian likelihood with small epsilon to avoid zero weights (using constant memory)\n",
        "    float variance = c_measurement_noise * c_measurement_noise;\n",
        "    float likelihood = __expf(-dist_sq / (2.0f * variance)) + 1e-10f;\n",
        "\n",
        "    // Store weight\n",
        "    weights[idx] = likelihood;\n",
        "}\n",
        "\n",
        "/* =================================================== */\n",
        "/* WEIGHT NORMALIZATION                                */\n",
        "/* =================================================== */\n",
        "\n",
        "/**\n",
        " * Normalizes weights and cumulative weights\n",
        " * Optimized for coalesced memory access\n",
        " *\n",
        " * @param weights: Input/output normalized weights\n",
        " * @param cumulative_weights: Input/output normalized cumulative weights\n",
        " * @param n: Number of particles\n",
        " * @param total_weight: Sum of all weights\n",
        " */\n",
        "__global__ void normalize_weights_kernel(\n",
        "    float* __restrict__ weights,\n",
        "    float* __restrict__ cumulative_weights,\n",
        "    int n,\n",
        "    float total_weight\n",
        ") {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (idx >= n) return;\n",
        "\n",
        "    // Avoid division by zero\n",
        "    float norm_factor = (total_weight > 1e-10f) ? (1.0f / total_weight) : (1.0f / n);\n",
        "\n",
        "    // Normalize both arrays in a single kernel launch\n",
        "    weights[idx] *= norm_factor;\n",
        "    cumulative_weights[idx] *= norm_factor;\n",
        "}\n",
        "\n",
        "/* =================================================== */\n",
        "/* SYSTEMATIC RESAMPLING                               */\n",
        "/* =================================================== */\n",
        "\n",
        "/**\n",
        " * Performs systematic resampling using binary search\n",
        " * Optimized version with:\n",
        " * - Coalesced memory access for input particles\n",
        " * - Efficient binary search (avoids linear search divergence)\n",
        " * - Strided writes to avoid bank conflicts\n",
        " *\n",
        " * @param particles_in: Input particles (to be resampled)\n",
        " * @param particles_out: Output resampled particles\n",
        " * @param cumulative_weights: Normalized cumulative weights\n",
        " * @param n: Number of particles\n",
        " * @param random_offset: Random offset for systematic resampling\n",
        " */\n",
        "__global__ void resample_kernel(\n",
        "    const Particle* __restrict__ particles_in,\n",
        "    Particle* __restrict__ particles_out,\n",
        "    const float* __restrict__ cumulative_weights,\n",
        "    int n,\n",
        "    float random_offset\n",
        ") {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (idx >= n) return;\n",
        "\n",
        "    // Compute systematic sample position\n",
        "    float position = random_offset + (float)idx / n;\n",
        "\n",
        "    // Binary search for the particle to resample\n",
        "    // This is much more efficient than linear search for large N\n",
        "    int left = 0;\n",
        "    int right = n - 1;\n",
        "    int selected_idx = 0;\n",
        "\n",
        "    // Unrolled binary search for better performance\n",
        "    #pragma unroll 8\n",
        "    while (left <= right) {\n",
        "        int mid = (left + right) >> 1;\n",
        "        float cum_weight = cumulative_weights[mid];\n",
        "\n",
        "        if (cum_weight < position) {\n",
        "            left = mid + 1;\n",
        "        } else {\n",
        "            selected_idx = mid;\n",
        "            right = mid - 1;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Copy selected particle to output (coalesced write)\n",
        "    particles_out[idx] = particles_in[selected_idx];\n",
        "}\n",
        "\n",
        "/* =================================================== */\n",
        "/* OPTIMIZED RESAMPLING WITH SHARED MEMORY             */\n",
        "/* =================================================== */\n",
        "\n",
        "/**\n",
        " * Advanced resampling kernel using shared memory caching\n",
        " * Further optimized for large particle counts\n",
        " *\n",
        " * Loads cumulative weights into shared memory in blocks\n",
        " * to reduce global memory accesses during binary search\n",
        " */\n",
        "__global__ void resample_optimized_kernel(\n",
        "    const Particle* __restrict__ particles_in,\n",
        "    Particle* __restrict__ particles_out,\n",
        "    cudaTextureObject_t tex_weights_obj,\n",
        "    int n,\n",
        "    float random_offset\n",
        ") {\n",
        "    __shared__ float s_cum_weights[THREADS_PER_BLOCK + 1];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (idx >= n) return;\n",
        "\n",
        "    // Compute systematic sample position\n",
        "    float position = random_offset + (float)idx / n;\n",
        "\n",
        "    // Collaborative loading of cumulative weights to shared memory\n",
        "    // Each block loads a window of cumulative weights\n",
        "    int block_start = blockIdx.x * blockDim.x;\n",
        "    if (tid < blockDim.x && block_start + tid < n) {\n",
        "        s_cum_weights[tid] = tex1Dfetch<float>(tex_weights_obj, block_start + tid);\n",
        "    }\n",
        "    if (tid == 0 && block_start + blockDim.x < n) {\n",
        "        s_cum_weights[blockDim.x] = tex1Dfetch<float>(tex_weights_obj, block_start + blockDim.x);\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    // Fast path: check if position is in current block's range\n",
        "    int selected_idx;\n",
        "    if (block_start > 0 && position < tex1Dfetch<float>(tex_weights_obj, block_start - 1)) {\n",
        "        // Need to search in previous blocks - use binary search on global memory\n",
        "        int left = 0;\n",
        "        int right = block_start - 1;\n",
        "        selected_idx = 0;\n",
        "\n",
        "        while (left <= right) {\n",
        "            int mid = (left + right) >> 1;\n",
        "            if (tex1Dfetch<float>(tex_weights_obj, mid) < position) {\n",
        "                left = mid + 1;\n",
        "            } else {\n",
        "                selected_idx = mid;\n",
        "                right = mid - 1;\n",
        "            }\n",
        "        }\n",
        "    } else if (block_start + blockDim.x < n &&\n",
        "               position >= s_cum_weights[blockDim.x - 1]) {\n",
        "        // Need to search in later blocks\n",
        "        int left = block_start + blockDim.x;\n",
        "        int right = n - 1;\n",
        "        selected_idx = left;\n",
        "\n",
        "        while (left <= right) {\n",
        "            int mid = (left + right) >> 1;\n",
        "            if (tex1Dfetch<float>(tex_weights_obj, mid) < position) {\n",
        "                left = mid + 1;\n",
        "            } else {\n",
        "                selected_idx = mid;\n",
        "                right = mid - 1;\n",
        "            }\n",
        "        }\n",
        "    } else {\n",
        "        // Position is in current block - search in shared memory\n",
        "        int left = 0;\n",
        "        int right = min(blockDim.x - 1, n - block_start - 1);\n",
        "        int local_idx = 0;\n",
        "\n",
        "        while (left <= right) {\n",
        "            int mid = (left + right) >> 1;\n",
        "            if (s_cum_weights[mid] < position) {\n",
        "                left = mid + 1;\n",
        "            } else {\n",
        "                local_idx = mid;\n",
        "                right = mid - 1;\n",
        "            }\n",
        "        }\n",
        "        selected_idx = block_start + local_idx;\n",
        "    }\n",
        "\n",
        "    // Copy selected particle (coalesced write)\n",
        "    particles_out[idx] = particles_in[selected_idx];\n",
        "}\n",
        "\n",
        "/* =================================================== */\n",
        "/* UTILITY KERNELS                                     */\n",
        "/* =================================================== */\n",
        "\n",
        "/**\n",
        " * Sets all weights to a uniform value\n",
        " * Used after resampling to reset particle weights\n",
        " */\n",
        "__global__ void set_uniform_weights_kernel(\n",
        "    float* __restrict__ weights,\n",
        "    int n,\n",
        "    float value\n",
        ") {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) {\n",
        "        weights[idx] = value;\n",
        "    }\n",
        "}\n",
        "\n",
        "} // extern \"C\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY9aepJdLYv_",
        "outputId": "577cda59-bdc8-4994-be4e-39ec6e4965ab"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting particle_filter_kernels.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile utils.cu\n",
        "#include \"particle_filter_config.h\"\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <time.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "/* =================================================== */\n",
        "/* HOST RANDOM NUMBER GENERATION                       */\n",
        "/* =================================================== */\n",
        "\n",
        "/**\n",
        " * Box-Muller transform for generating Gaussian random numbers on host\n",
        " * Used for generating noisy observations\n",
        " */\n",
        "float randn_host(float mean, float stddev) {\n",
        "    static int has_spare = 0;\n",
        "    static float spare;\n",
        "\n",
        "    if (has_spare) {\n",
        "        has_spare = 0;\n",
        "        return mean + stddev * spare;\n",
        "    }\n",
        "\n",
        "    has_spare = 1;\n",
        "    float u, v, s;\n",
        "\n",
        "    do {\n",
        "        u = (rand() / ((float)RAND_MAX)) * 2.0f - 1.0f;\n",
        "        v = (rand() / ((float)RAND_MAX)) * 2.0f - 1.0f;\n",
        "        s = u * u + v * v;\n",
        "    } while (s >= 1.0f || s == 0.0f);\n",
        "\n",
        "    s = sqrtf(-2.0f * logf(s) / s);\n",
        "    spare = v * s;\n",
        "    return mean + stddev * u * s;\n",
        "}\n",
        "\n",
        "/* =================================================== */\n",
        "/* FILE I/O UTILITIES                                  */\n",
        "/* =================================================== */\n",
        "\n",
        "/**\n",
        " * Opens a file with error checking\n",
        " */\n",
        "FILE* safe_fopen(const char* filename, const char* mode) {\n",
        "    FILE* file = fopen(filename, mode);\n",
        "    if (!file) {\n",
        "        fprintf(stderr, \"Error: Could not open file %s\\n\", filename);\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "    return file;\n",
        "}\n",
        "\n",
        "/**\n",
        " * Writes result to CSV file\n",
        " */\n",
        "void write_result(FILE* file, const Result* result) {\n",
        "    fprintf(file, \"%f,%f,%f,%f,%f,%f,%f,%f\\n\",\n",
        "            result->time,\n",
        "            result->true_x, result->true_y,\n",
        "            result->obs_x, result->obs_y,\n",
        "            result->est_x, result->est_y,\n",
        "            result->error);\n",
        "}\n",
        "\n",
        "/**\n",
        " * Writes particle data to CSV file (for visualization)\n",
        " */\n",
        "void write_particles(\n",
        "    FILE* file,\n",
        "    int timestep,\n",
        "    const Particle* h_particles,\n",
        "    const float* h_weights,\n",
        "    int n_particles\n",
        ") {\n",
        "    for (int i = 0; i < n_particles; ++i) {\n",
        "        fprintf(file, \"%d,%f,%f,%f\\n\",\n",
        "                timestep,\n",
        "                h_particles[i].x,\n",
        "                h_particles[i].y,\n",
        "                h_weights[i]);\n",
        "    }\n",
        "}\n",
        "\n",
        "/* =================================================== */\n",
        "/* MEMORY ALLOCATION UTILITIES                         */\n",
        "/* =================================================== */\n",
        "\n",
        "/**\n",
        " * Allocates pinned (page-locked) host memory for faster transfers\n",
        " * Pinned memory allows asynchronous copies and higher bandwidth\n",
        " */\n",
        "void* allocate_pinned_memory(size_t size) {\n",
        "    void* ptr;\n",
        "    CUDA_CHECK(cudaMallocHost(&ptr, size));\n",
        "    return ptr;\n",
        "}\n",
        "\n",
        "/**\n",
        " * Frees pinned host memory\n",
        " */\n",
        "void free_pinned_memory(void* ptr) {\n",
        "    CUDA_CHECK(cudaFreeHost(ptr));\n",
        "}\n",
        "\n",
        "/* =================================================== */\n",
        "/* DEVICE INFORMATION                                  */\n",
        "/* =================================================== */\n",
        "\n",
        "/**\n",
        " * Prints GPU device information\n",
        " * Useful for understanding performance characteristics\n",
        " */\n",
        "void print_device_info() {\n",
        "    int device;\n",
        "    CUDA_CHECK(cudaGetDevice(&device));\n",
        "\n",
        "    cudaDeviceProp prop;\n",
        "    CUDA_CHECK(cudaGetDeviceProperties(&prop, device));\n",
        "\n",
        "    printf(\"\\n=== GPU Device Information ===\\n\");\n",
        "    printf(\"Device: %s\\n\", prop.name);\n",
        "    printf(\"Compute Capability: %d.%d\\n\", prop.major, prop.minor);\n",
        "    printf(\"Total Global Memory: %.2f GB\\n\",\n",
        "           prop.totalGlobalMem / (1024.0 * 1024.0 * 1024.0));\n",
        "    printf(\"Multiprocessors: %d\\n\", prop.multiProcessorCount);\n",
        "    printf(\"Max Threads per Block: %d\\n\", prop.maxThreadsPerBlock);\n",
        "    printf(\"Warp Size: %d\\n\", prop.warpSize);\n",
        "    printf(\"Shared Memory per Block: %.2f KB\\n\",\n",
        "           prop.sharedMemPerBlock / 1024.0);\n",
        "    printf(\"==============================\\n\\n\");\n",
        "}\n",
        "\n",
        "/* =================================================== */\n",
        "/* PERFORMANCE TIMING                                  */\n",
        "/* =================================================== */\n",
        "\n",
        "/**\n",
        " * Simple timer structure for CPU timing\n",
        " */\n",
        "typedef struct {\n",
        "    clock_t start;\n",
        "    clock_t end;\n",
        "} CPUTimer;\n",
        "\n",
        "/**\n",
        " * GPU timer using CUDA events\n",
        " */\n",
        "typedef struct {\n",
        "    cudaEvent_t start;\n",
        "    cudaEvent_t stop;\n",
        "} GPUTimer;\n",
        "\n",
        "void cpu_timer_start(CPUTimer* timer) {\n",
        "    timer->start = clock();\n",
        "}\n",
        "\n",
        "float cpu_timer_stop(CPUTimer* timer) {\n",
        "    timer->end = clock();\n",
        "    return ((float)(timer->end - timer->start)) / CLOCKS_PER_SEC;\n",
        "}\n",
        "\n",
        "void gpu_timer_create(GPUTimer* timer) {\n",
        "    CUDA_CHECK(cudaEventCreate(&timer->start));\n",
        "    CUDA_CHECK(cudaEventCreate(&timer->stop));\n",
        "}\n",
        "\n",
        "void gpu_timer_start(GPUTimer* timer) {\n",
        "    CUDA_CHECK(cudaEventRecord(timer->start));\n",
        "}\n",
        "\n",
        "float gpu_timer_stop(GPUTimer* timer) {\n",
        "    CUDA_CHECK(cudaEventRecord(timer->stop));\n",
        "    CUDA_CHECK(cudaEventSynchronize(timer->stop));\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    CUDA_CHECK(cudaEventElapsedTime(&milliseconds, timer->start, timer->stop));\n",
        "    return milliseconds / 1000.0f; // Convert to seconds\n",
        "}\n",
        "\n",
        "void gpu_timer_destroy(GPUTimer* timer) {\n",
        "    CUDA_CHECK(cudaEventDestroy(timer->start));\n",
        "    CUDA_CHECK(cudaEventDestroy(timer->stop));\n",
        "}\n",
        "\n",
        "/* =================================================== */\n",
        "/* STATISTICS UTILITIES                                */\n",
        "/* =================================================== */\n",
        "\n",
        "/**\n",
        " * Computes RMSE from array of errors\n",
        " */\n",
        "float compute_rmse(const float* errors, int n) {\n",
        "    float sum = 0.0f;\n",
        "    for (int i = 0; i < n; ++i) {\n",
        "        sum += errors[i] * errors[i];\n",
        "    }\n",
        "    return sqrtf(sum / n);\n",
        "}\n",
        "\n",
        "/**\n",
        " * Computes mean of array\n",
        " */\n",
        "float compute_mean(const float* values, int n) {\n",
        "    float sum = 0.0f;\n",
        "    for (int i = 0; i < n; ++i) {\n",
        "        sum += values[i];\n",
        "    }\n",
        "    return sum / n;\n",
        "}\n",
        "\n",
        "/**\n",
        " * Computes standard deviation\n",
        " */\n",
        "float compute_stddev(const float* values, int n, float mean) {\n",
        "    float sum_sq = 0.0f;\n",
        "    for (int i = 0; i < n; ++i) {\n",
        "        float diff = values[i] - mean;\n",
        "        sum_sq += diff * diff;\n",
        "    }\n",
        "    return sqrtf(sum_sq / n);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8HPf21RLd9d",
        "outputId": "5317a818-61ca-4cc7-b00b-cbbb9c7db3a8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting utils.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile particle_filter_main.cu\n",
        "// particle_filter_main.cu\n",
        "// Main program for optimized CUDA particle filter\n",
        "// Integrates all components with multi-stream execution\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <string.h>\n",
        "\n",
        "#include \"particle_filter_config.h\"\n",
        "\n",
        "// GPU Timer structure\n",
        "typedef struct {\n",
        "    cudaEvent_t start;\n",
        "    cudaEvent_t stop;\n",
        "} GPUTimer;\n",
        "\n",
        "// Forward declarations for external functions\n",
        "extern void inclusive_scan(const float*, float*, int, cudaStream_t);\n",
        "extern float reduce_sum(const float*, int, cudaStream_t);\n",
        "extern float reduce_sum_squares(const float*, int, cudaStream_t);\n",
        "extern void weighted_average(const Particle*, const float*, int, float*, float*, cudaStream_t);\n",
        "extern void debug_simple_average(const Particle*, int, float*, float*, cudaStream_t);\n",
        "\n",
        "// Forward declarations for kernel launches\n",
        "extern \"C\" {\n",
        "    __global__ void init_particles_kernel(Particle*, curandState*, int, float, float);\n",
        "    __global__ void predict_kernel(Particle*, curandState*, int);\n",
        "    __global__ void update_weights_kernel(const Particle*, float*, int, float, float);\n",
        "    __global__ void normalize_weights_kernel(float*, float*, int, float);\n",
        "    __global__ void resample_kernel(const Particle*, Particle*, const float*, int, float);\n",
        "    __global__ void resample_optimized_kernel(const Particle*, Particle*, cudaTextureObject_t, int, float);\n",
        "    __global__ void set_uniform_weights_kernel(float*, int, float);\n",
        "}\n",
        "\n",
        "// Utility functions\n",
        "extern float randn_host(float, float);\n",
        "extern FILE* safe_fopen(const char*, const char*);\n",
        "extern void write_result(FILE*, const Result*);\n",
        "extern void print_device_info();\n",
        "extern void gpu_timer_create(GPUTimer*);\n",
        "extern void gpu_timer_start(GPUTimer*);\n",
        "extern float gpu_timer_stop(GPUTimer*);\n",
        "extern void gpu_timer_destroy(GPUTimer*);\n",
        "extern float compute_rmse(const float*, int);\n",
        "extern float compute_mean(const float*, int);\n",
        "extern float compute_stddev(const float*, int, float);\n",
        "\n",
        "// Trajectory generation (also in kernels file)\n",
        "extern void generate_trajectory(float, float*, float*);\n",
        "\n",
        "/* =================================================== */\n",
        "/* PARTICLE FILTER STATE STRUCTURE                     */\n",
        "/* =================================================== */\n",
        "\n",
        "typedef struct {\n",
        "    // Device memory\n",
        "    Particle* d_particles[2];      // Double buffer for resampling\n",
        "    float* d_weights;\n",
        "    float* d_cumulative_weights;\n",
        "    curandState* d_rand_states;\n",
        "\n",
        "    // Texture object for weights\n",
        "    cudaTextureObject_t tex_weights_obj;\n",
        "\n",
        "    // Pinned host memory for async transfers\n",
        "    float* h_est_x_pinned;\n",
        "    float* h_est_y_pinned;\n",
        "\n",
        "    // CUDA streams for concurrent execution\n",
        "    cudaStream_t streams[NUM_STREAMS];\n",
        "\n",
        "    // Configuration\n",
        "    int n_particles;\n",
        "    int current_buffer;\n",
        "\n",
        "    // Grid configuration\n",
        "    int threads_per_block;\n",
        "    int blocks_per_grid;\n",
        "} ParticleFilterState;\n",
        "\n",
        "/* =================================================== */\n",
        "/* INITIALIZATION                                      */\n",
        "/* =================================================== */\n",
        "\n",
        "/**\n",
        " * Initializes the particle filter state\n",
        " * Allocates all GPU and pinned host memory\n",
        " * Creates CUDA streams for concurrent execution\n",
        " */\n",
        "void initialize_particle_filter(ParticleFilterState* pf, int n_particles) {\n",
        "    pf->n_particles = n_particles;\n",
        "    pf->current_buffer = 0;\n",
        "    pf->threads_per_block = THREADS_PER_BLOCK;\n",
        "    pf->blocks_per_grid = GRID_SIZE(n_particles, THREADS_PER_BLOCK);\n",
        "\n",
        "    printf(\"Initializing Particle Filter...\\n\");\n",
        "    printf(\"Particles: %d\\n\", n_particles);\n",
        "    printf(\"Blocks: %d, Threads per block: %d\\n\",\n",
        "           pf->blocks_per_grid, pf->threads_per_block);\n",
        "\n",
        "    // Allocate device memory\n",
        "    size_t particle_size = n_particles * sizeof(Particle);\n",
        "    size_t float_size = n_particles * sizeof(float);\n",
        "    size_t state_size = n_particles * sizeof(curandState);\n",
        "\n",
        "    CUDA_CHECK(cudaMalloc(&pf->d_particles[0], particle_size));\n",
        "    CUDA_CHECK(cudaMalloc(&pf->d_particles[1], particle_size));\n",
        "    CUDA_CHECK(cudaMalloc(&pf->d_weights, float_size));\n",
        "    CUDA_CHECK(cudaMalloc(&pf->d_cumulative_weights, float_size));\n",
        "    CUDA_CHECK(cudaMalloc(&pf->d_rand_states, state_size));\n",
        "\n",
        "    // Allocate pinned host memory for faster transfers\n",
        "    CUDA_CHECK(cudaMallocHost(&pf->h_est_x_pinned, sizeof(float)));\n",
        "    CUDA_CHECK(cudaMallocHost(&pf->h_est_y_pinned, sizeof(float)));\n",
        "\n",
        "    // Create CUDA streams\n",
        "    for (int i = 0; i < NUM_STREAMS; ++i) {\n",
        "        CUDA_CHECK(cudaStreamCreate(&pf->streams[i]));\n",
        "    }\n",
        "\n",
        "    printf(\"Memory allocated successfully\\n\");\n",
        "    printf(\"Total GPU memory used: %.2f MB\\n\",\n",
        "           (2 * particle_size + 2 * float_size + state_size) / (1024.0 * 1024.0));\n",
        "}\n",
        "\n",
        "/**\n",
        " * Initializes particles around initial position\n",
        " */\n",
        "void initialize_particles(ParticleFilterState* pf, float init_x, float init_y) {\n",
        "    printf(\"Launching init_particles_kernel with %d blocks, %d threads\\n\",\n",
        "           pf->blocks_per_grid, pf->threads_per_block);\n",
        "\n",
        "    init_particles_kernel<<<pf->blocks_per_grid, pf->threads_per_block>>>(\n",
        "        pf->d_particles[0],\n",
        "        pf->d_rand_states,\n",
        "        pf->n_particles,\n",
        "        init_x,\n",
        "        init_y\n",
        "    );\n",
        "\n",
        "    // Check for kernel launch errors\n",
        "    cudaError_t launch_error = cudaGetLastError();\n",
        "    if (launch_error != cudaSuccess) {\n",
        "        printf(\"ERROR: Kernel launch failed: %s\\n\", cudaGetErrorString(launch_error));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    CUDA_CHECK(cudaDeviceSynchronize());\n",
        "\n",
        "    // Check for kernel execution errors\n",
        "    cudaError_t exec_error = cudaGetLastError();\n",
        "    if (exec_error != cudaSuccess) {\n",
        "        printf(\"ERROR: Kernel execution failed: %s\\n\", cudaGetErrorString(exec_error));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    printf(\"Particles initialized at (%.2f, %.2f)\\n\", init_x, init_y);\n",
        "\n",
        "    // Debug: Check first few particles\n",
        "    Particle* h_particles = (Particle*)malloc(10 * sizeof(Particle));\n",
        "    CUDA_CHECK(cudaMemcpy(h_particles, pf->d_particles[0], 10 * sizeof(Particle), cudaMemcpyDeviceToHost));\n",
        "    printf(\"DEBUG: First 3 particles after init:\\n\");\n",
        "    for (int i = 0; i < 3; i++) {\n",
        "        printf(\"  Particle %d: x=%.6f, y=%.6f, vx=%.6f, vy=%.6f\\n\",\n",
        "               i, h_particles[i].x, h_particles[i].y, h_particles[i].vx, h_particles[i].vy);\n",
        "    }\n",
        "    free(h_particles);\n",
        "}\n",
        "\n",
        "/* =================================================== */\n",
        "/* PARTICLE FILTER STEP                                */\n",
        "/* =================================================== */\n",
        "\n",
        "/**\n",
        " * Executes one complete particle filter iteration\n",
        " * Uses streams for overlapping computation where possible\n",
        " *\n",
        " * @return: Estimated state (x, y) and error\n",
        " */\n",
        "Result particle_filter_step(\n",
        "    ParticleFilterState* pf,\n",
        "    float time,\n",
        "    float obs_x,\n",
        "    float obs_y,\n",
        "    float true_x,\n",
        "    float true_y\n",
        ") {\n",
        "    // Select current particle buffer\n",
        "    int curr_buf = pf->current_buffer;\n",
        "    Particle* d_particles_curr = pf->d_particles[curr_buf];\n",
        "    Particle* d_particles_next = pf->d_particles[1 - curr_buf];\n",
        "\n",
        "    // Assign streams for different phases\n",
        "    cudaStream_t predict_stream = pf->streams[0];\n",
        "    cudaStream_t weight_stream = pf->streams[1];\n",
        "    cudaStream_t scan_stream = pf->streams[2];\n",
        "    cudaStream_t resample_stream = pf->streams[3];\n",
        "\n",
        "    // ============ PREDICTION STEP ============\n",
        "    predict_kernel<<<pf->blocks_per_grid, pf->threads_per_block, 0, predict_stream>>>(\n",
        "        d_particles_curr,\n",
        "        pf->d_rand_states,\n",
        "        pf->n_particles\n",
        "    );\n",
        "\n",
        "    // Wait for prediction to complete before weight update (data dependency)\n",
        "    CUDA_CHECK(cudaStreamSynchronize(predict_stream));\n",
        "\n",
        "    // Debug: Check particles after prediction (only for first timestep)\n",
        "    if (time < 0.01f) {  // Only for t=0\n",
        "        Particle* h_particles = (Particle*)malloc(3 * sizeof(Particle));\n",
        "        CUDA_CHECK(cudaMemcpy(h_particles, d_particles_curr, 3 * sizeof(Particle), cudaMemcpyDeviceToHost));\n",
        "        printf(\"DEBUG: First 3 particles after prediction at t=%.1f:\\n\", time);\n",
        "        for (int i = 0; i < 3; i++) {\n",
        "            printf(\"  Particle %d: x=%.6f, y=%.6f, vx=%.6f, vy=%.6f\\n\",\n",
        "                   i, h_particles[i].x, h_particles[i].y, h_particles[i].vx, h_particles[i].vy);\n",
        "        }\n",
        "        free(h_particles);\n",
        "    }\n",
        "\n",
        "    // ============ UPDATE WEIGHTS ============\n",
        "    update_weights_kernel<<<pf->blocks_per_grid, pf->threads_per_block, 0, weight_stream>>>(\n",
        "        d_particles_curr,\n",
        "        pf->d_weights,\n",
        "        pf->n_particles,\n",
        "        obs_x,\n",
        "        obs_y\n",
        "    );\n",
        "\n",
        "    // ============ COMPUTE CUMULATIVE WEIGHTS ============\n",
        "    // Wait for weight update to complete before scan\n",
        "    CUDA_CHECK(cudaStreamSynchronize(weight_stream));\n",
        "\n",
        "    // Perform inclusive scan (prefix sum) on weights\n",
        "    inclusive_scan(\n",
        "        pf->d_weights,\n",
        "        pf->d_cumulative_weights,\n",
        "        pf->n_particles,\n",
        "        scan_stream\n",
        "    );\n",
        "\n",
        "    // Get total weight (last element of cumulative sum)\n",
        "    float total_weight;\n",
        "    CUDA_CHECK(cudaMemcpyAsync(\n",
        "        &total_weight,\n",
        "        pf->d_cumulative_weights + pf->n_particles - 1,\n",
        "        sizeof(float),\n",
        "        cudaMemcpyDeviceToHost,\n",
        "        scan_stream\n",
        "    ));\n",
        "    CUDA_CHECK(cudaStreamSynchronize(scan_stream));\n",
        "\n",
        "    // ============ NORMALIZE WEIGHTS ============\n",
        "    normalize_weights_kernel<<<pf->blocks_per_grid, pf->threads_per_block, 0, scan_stream>>>(\n",
        "        pf->d_weights,\n",
        "        pf->d_cumulative_weights,\n",
        "        pf->n_particles,\n",
        "        total_weight\n",
        "    );\n",
        "\n",
        "    // ============ COMPUTE ESS (Effective Sample Size) ============\n",
        "    // Can overlap with state estimation\n",
        "    float sum_weights_squared = reduce_sum_squares(\n",
        "        pf->d_weights,\n",
        "        pf->n_particles,\n",
        "        scan_stream\n",
        "    );\n",
        "    float ess = 1.0f / sum_weights_squared;\n",
        "\n",
        "    // ============ RESAMPLING (if needed) ============\n",
        "    float ess_threshold = pf->n_particles / 2.0f;\n",
        "    if (ess < ess_threshold) {\n",
        "        // Wait for normalization to complete before resampling\n",
        "        CUDA_CHECK(cudaStreamSynchronize(scan_stream));\n",
        "\n",
        "        // Create texture object for weight access\n",
        "        cudaResourceDesc resDesc = {};\n",
        "        resDesc.resType = cudaResourceTypeLinear;\n",
        "        resDesc.res.linear.devPtr = pf->d_cumulative_weights;\n",
        "        resDesc.res.linear.desc.f = cudaChannelFormatKindFloat;\n",
        "        resDesc.res.linear.desc.x = 32; // bits per channel\n",
        "        resDesc.res.linear.sizeInBytes = pf->n_particles * sizeof(float);\n",
        "\n",
        "        cudaTextureDesc texDesc = {};\n",
        "        texDesc.readMode = cudaReadModeElementType;\n",
        "\n",
        "        CUDA_CHECK(cudaCreateTextureObject(&pf->tex_weights_obj, &resDesc, &texDesc, NULL));\n",
        "\n",
        "        // Generate random offset for systematic resampling\n",
        "        float random_offset = ((float)rand() / RAND_MAX) / pf->n_particles;\n",
        "\n",
        "        // Use optimized resampling kernel with shared memory\n",
        "        resample_optimized_kernel<<<pf->blocks_per_grid, pf->threads_per_block, 0, resample_stream>>>(\n",
        "            d_particles_curr,\n",
        "            d_particles_next,\n",
        "            pf->tex_weights_obj,\n",
        "            pf->n_particles,\n",
        "            random_offset\n",
        "        );\n",
        "\n",
        "        // Destroy texture object\n",
        "        CUDA_CHECK(cudaDestroyTextureObject(pf->tex_weights_obj));\n",
        "\n",
        "        // Swap buffers\n",
        "        pf->current_buffer = 1 - curr_buf;\n",
        "\n",
        "        // Reset weights to uniform after resampling\n",
        "        float uniform_weight = 1.0f / pf->n_particles;\n",
        "        set_uniform_weights_kernel<<<pf->blocks_per_grid, pf->threads_per_block, 0, resample_stream>>>(\n",
        "            pf->d_weights, pf->n_particles, uniform_weight\n",
        "        );\n",
        "    }\n",
        "\n",
        "    // ============ STATE ESTIMATION ============\n",
        "    float est_x = -999.0f, est_y = -999.0f;  // Initialize to obvious wrong values to detect bugs\n",
        "\n",
        "    // Use proper weighted average for state estimation\n",
        "    // Can overlap with ESS calculation and resampling decision\n",
        "    weighted_average(\n",
        "        pf->d_particles[pf->current_buffer],\n",
        "        pf->d_weights,\n",
        "        pf->n_particles,\n",
        "        &est_x,\n",
        "        &est_y,\n",
        "        resample_stream\n",
        "    );\n",
        "\n",
        "    // ============ COMPUTE ERROR ============\n",
        "    float dx = est_x - true_x;\n",
        "    float dy = est_y - true_y;\n",
        "    float error = sqrtf(dx * dx + dy * dy);\n",
        "\n",
        "    // Create result\n",
        "    Result result;\n",
        "    result.time = time;\n",
        "    result.true_x = true_x;\n",
        "    result.true_y = true_y;\n",
        "    result.obs_x = obs_x;\n",
        "    result.obs_y = obs_y;\n",
        "    result.est_x = est_x;\n",
        "    result.est_y = est_y;\n",
        "    result.error = error;\n",
        "\n",
        "    return result;\n",
        "}\n",
        "\n",
        "/* =================================================== */\n",
        "/* CLEANUP                                             */\n",
        "/* =================================================== */\n",
        "\n",
        "void cleanup_particle_filter(ParticleFilterState* pf) {\n",
        "    // Free device memory\n",
        "    CUDA_CHECK(cudaFree(pf->d_particles[0]));\n",
        "    CUDA_CHECK(cudaFree(pf->d_particles[1]));\n",
        "    CUDA_CHECK(cudaFree(pf->d_weights));\n",
        "    CUDA_CHECK(cudaFree(pf->d_cumulative_weights));\n",
        "    CUDA_CHECK(cudaFree(pf->d_rand_states));\n",
        "\n",
        "    // Free pinned host memory\n",
        "    CUDA_CHECK(cudaFreeHost(pf->h_est_x_pinned));\n",
        "    CUDA_CHECK(cudaFreeHost(pf->h_est_y_pinned));\n",
        "\n",
        "    // Destroy streams\n",
        "    for (int i = 0; i < NUM_STREAMS; ++i) {\n",
        "        CUDA_CHECK(cudaStreamDestroy(pf->streams[i]));\n",
        "    }\n",
        "}\n",
        "\n",
        "/* =================================================== */\n",
        "/* MAIN PROGRAM                                        */\n",
        "/* =================================================== */\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "    // Seed random number generator\n",
        "    srand(time(NULL));\n",
        "\n",
        "    printf(\"\\n\");\n",
        "    printf(\"============================================\\n\");\n",
        "    printf(\"  OPTIMIZED CUDA PARTICLE FILTER\\n\");\n",
        "    printf(\"============================================\\n\");\n",
        "\n",
        "    // Print device information\n",
        "    print_device_info();\n",
        "\n",
        "    // Open output files\n",
        "    FILE* results_file = safe_fopen(\"results_gpu_optimized.csv\", \"w\");\n",
        "    fprintf(results_file, \"time,true_x,true_y,obs_x,obs_y,est_x,est_y,error\\n\");\n",
        "\n",
        "    // Initialize particle filter\n",
        "    ParticleFilterState pf;\n",
        "    initialize_particle_filter(&pf, N_PARTICLES);\n",
        "\n",
        "    // Get initial position from trajectory\n",
        "    float init_x, init_y;\n",
        "    generate_trajectory(0.0f, &init_x, &init_y);\n",
        "    initialize_particles(&pf, init_x, init_y);\n",
        "\n",
        "    // Start timing\n",
        "    GPUTimer timer;\n",
        "    gpu_timer_create(&timer);\n",
        "    gpu_timer_start(&timer);\n",
        "\n",
        "    printf(\"\\n\");\n",
        "    printf(\"============================================\\n\");\n",
        "    printf(\"  RUNNING SIMULATION\\n\");\n",
        "    printf(\"============================================\\n\");\n",
        "    printf(\"Timesteps: %d, dt: %.2f\\n\\n\", N_TIMESTEPS, DT);\n",
        "\n",
        "    // Arrays for statistics\n",
        "    float* errors = (float*)malloc(N_TIMESTEPS * sizeof(float));\n",
        "\n",
        "    // ============ MAIN SIMULATION LOOP ============\n",
        "    for (int t = 0; t < N_TIMESTEPS; ++t) {\n",
        "        float time = t * DT;\n",
        "\n",
        "        // Generate true trajectory and noisy observation\n",
        "        float true_x, true_y;\n",
        "        generate_trajectory(time, &true_x, &true_y);\n",
        "\n",
        "        float obs_x = true_x + randn_host(0.0f, MEASUREMENT_NOISE);\n",
        "        float obs_y = true_y + randn_host(0.0f, MEASUREMENT_NOISE);\n",
        "\n",
        "        // Execute particle filter step\n",
        "        Result result = particle_filter_step(\n",
        "            &pf, time, obs_x, obs_y, true_x, true_y\n",
        "        );\n",
        "\n",
        "        // Store error\n",
        "        errors[t] = result.error;\n",
        "\n",
        "        // Write result to file\n",
        "        write_result(results_file, &result);\n",
        "\n",
        "        // Print progress\n",
        "        if (t % 10 == 0 || t == N_TIMESTEPS - 1) {\n",
        "            printf(\"t=%3d: true=(%.2f,%.2f) obs=(%.2f,%.2f) est=(%.2f,%.2f) error=%.3f\\n\",\n",
        "                   t, true_x, true_y, obs_x, obs_y, result.est_x, result.est_y, result.error);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Stop timing\n",
        "    float total_time = gpu_timer_stop(&timer);\n",
        "    gpu_timer_destroy(&timer);\n",
        "\n",
        "    printf(\"\\n\");\n",
        "    printf(\"============================================\\n\");\n",
        "    printf(\"  SIMULATION COMPLETE\\n\");\n",
        "    printf(\"============================================\\n\");\n",
        "\n",
        "    // Compute and display statistics\n",
        "    float mean_error = compute_mean(errors, N_TIMESTEPS);\n",
        "    float rmse = compute_rmse(errors, N_TIMESTEPS);\n",
        "    float stddev = compute_stddev(errors, N_TIMESTEPS, mean_error);\n",
        "\n",
        "    printf(\"Performance Statistics:\\n\");\n",
        "    printf(\"Total simulation time: %.3f seconds\\n\", total_time);\n",
        "    printf(\"Average time per step: %.3f ms\\n\",\n",
        "           (total_time * 1000.0f) / N_TIMESTEPS);\n",
        "    printf(\"Throughput: %.1f particles/ms\\n\",\n",
        "           (N_PARTICLES * N_TIMESTEPS) / (total_time * 1000.0f));\n",
        "\n",
        "    printf(\"\\nAccuracy Statistics:\\n\");\n",
        "    printf(\"Mean error: %.3f\\n\", mean_error);\n",
        "    printf(\"RMSE: %.3f\\n\", rmse);\n",
        "    printf(\"Standard deviation: %.3f\\n\", stddev);\n",
        "    printf(\"Final error: %.3f\\n\", errors[N_TIMESTEPS - 1]);\n",
        "\n",
        "    // Cleanup\n",
        "    cleanup_particle_filter(&pf);\n",
        "    fclose(results_file);\n",
        "    free(errors);\n",
        "\n",
        "    printf(\"\\nResults saved to: results_gpu_optimized.csv\\n\");\n",
        "    printf(\"============================================\\n\");\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3_l7jYYLitx",
        "outputId": "d8ffd98a-7387-4b24-a338-f63b10384468"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting particle_filter_main.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc particle_filter_main.cu particle_filter_kernels.cu reduce_kernels.cu utils.cu scan_kernels.cu -lcurand -arch=sm_75 -o particle_filter"
      ],
      "metadata": {
        "id": "jrGKHXJFE_0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f193152-62ca-4bb3-81a2-210db326b1d5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mparticle_filter_main.cu(461)\u001b[0m: \u001b[01;35mwarning\u001b[0m #61-D: integer operation result is out of range\n",
            "             (100000000 * 100) / (total_time * 1000.0f));\n",
            "                        ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mparticle_filter_main.cu(461)\u001b[0m: \u001b[01;35mwarning\u001b[0m #61-D: integer operation result is out of range\n",
            "             (100000000 * 100) / (total_time * 1000.0f));\n",
            "                        ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[Kparticle_filter_main.cu:\u001b[m\u001b[K In function \u001b[01m\u001b[Kint main(int, char**)\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kparticle_filter_main.cu:460:54:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kinteger overflow in expression of type \u001b[01m\u001b[Kint\u001b[m\u001b[K results in \u001b[01m\u001b[K1410065408\u001b[m\u001b[K [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Woverflow\u0007-Woverflow\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  460 |     printf(\"Throughput: %.1f particles/ms\\n\u001b[01;35m\u001b[K\",\u001b[m\u001b[K\n",
            "      |                                            \u001b[01;35m\u001b[K~~\u001b[m\u001b[K        \u001b[01;35m\u001b[K^\u001b[m\u001b[K    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ./particle_filter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwTeTJLfGPdy",
        "outputId": "a169f906-de24-46ac-d190-49d15054d1b4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================\n",
            "  OPTIMIZED CUDA PARTICLE FILTER\n",
            "============================================\n",
            "\n",
            "=== GPU Device Information ===\n",
            "Device: Tesla T4\n",
            "Compute Capability: 7.5\n",
            "Total Global Memory: 14.74 GB\n",
            "Multiprocessors: 40\n",
            "Max Threads per Block: 1024\n",
            "Warp Size: 32\n",
            "Shared Memory per Block: 48.00 KB\n",
            "==============================\n",
            "\n",
            "Initializing Particle Filter...\n",
            "Particles: 100000000\n",
            "Blocks: 390625, Threads per block: 256\n",
            "Memory allocated successfully\n",
            "Total GPU memory used: 8392.33 MB\n",
            "Launching init_particles_kernel with 390625 blocks, 256 threads\n",
            "Particles initialized at (0.00, 0.00)\n",
            "DEBUG: First 3 particles after init:\n",
            "  Particle 0: x=0.390487, y=-0.900789, vx=3.014628, vy=-0.050546\n",
            "  Particle 1: x=-0.488467, y=-0.588114, vx=3.090725, vy=-0.201091\n",
            "  Particle 2: x=0.151813, y=-0.287802, vx=2.849078, vy=-0.084052\n",
            "\n",
            "============================================\n",
            "  RUNNING SIMULATION\n",
            "============================================\n",
            "Timesteps: 100, dt: 0.10\n",
            "\n",
            "DEBUG: First 3 particles after prediction at t=0.0:\n",
            "  Particle 0: x=0.683702, y=-0.920320, vx=3.004172, vy=-0.048088\n",
            "  Particle 1: x=-0.150119, y=-0.620391, vx=3.079228, vy=-0.195860\n",
            "  Particle 2: x=0.422578, y=-0.256606, vx=2.848959, vy=-0.085056\n",
            "t=  0: true=(0.00,0.00) obs=(-0.80,2.09) est=(0.08,0.42) error=0.423\n",
            "t= 10: true=(3.00,0.00) obs=(4.46,-1.21) est=(3.46,-0.65) error=0.796\n",
            "t= 20: true=(6.00,0.00) obs=(5.90,0.55) est=(6.16,-0.48) error=0.510\n",
            "t= 30: true=(9.00,0.50) obs=(9.74,0.10) est=(9.38,-0.83) error=1.386\n",
            "t= 40: true=(12.00,2.00) obs=(14.00,-0.15) est=(12.32,-0.96) error=2.979\n",
            "t= 50: true=(14.10,4.10) obs=(16.42,4.52) est=(14.89,0.68) error=3.508\n",
            "t= 60: true=(16.20,10.80) obs=(15.59,11.97) est=(17.86,0.75) error=10.182\n",
            "t= 70: true=(17.70,8.40) obs=(19.52,9.32) est=(20.97,0.49) error=8.562\n",
            "t= 80: true=(19.20,4.40) obs=(20.58,4.38) est=(23.70,1.05) error=5.606\n",
            "t= 90: true=(22.20,5.00) obs=(21.76,4.70) est=(24.44,0.81) error=4.754\n",
            "t= 99: true=(24.90,5.54) obs=(25.66,5.43) est=(26.93,0.87) error=5.092\n",
            "\n",
            "============================================\n",
            "  SIMULATION COMPLETE\n",
            "============================================\n",
            "Performance Statistics:\n",
            "Total simulation time: 11.328 seconds\n",
            "Average time per step: 113.279 ms\n",
            "Throughput: 124477.7 particles/ms\n",
            "\n",
            "Accuracy Statistics:\n",
            "Mean error: 3.842\n",
            "RMSE: 4.866\n",
            "Standard deviation: 2.987\n",
            "Final error: 5.092\n",
            "\n",
            "Results saved to: results_gpu_optimized.csv\n",
            "============================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv('results_gpu_optimized.csv')\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(df['true_x'], df['true_y'], 'g-', label='Traiettoria vera', linewidth=2)\n",
        "plt.plot(df['obs_x'], df['obs_y'], 'r.', label='Osservazioni', alpha=0.5, markersize=3)\n",
        "plt.plot(df['est_x'], df['est_y'], 'b-', label='Stima filtro', linewidth=2)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.axis('equal')\n",
        "plt.title('Particle Filter - Tracking 2D')\n",
        "plt.savefig('tracking_result.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "qpnQgLqr2LIc",
        "outputId": "96735e91-dc97-4ee4-e20c-307a8a5028f7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    \"\"\"Load trajectory and particle data\"\"\"\n",
        "    # Load trajectory data\n",
        "    trajectory_df = pd.read_csv('results_gpu_optimized.csv')\n",
        "\n",
        "    # Load particle data\n",
        "    particles_df = pd.read_csv('particles.csv')\n",
        "\n",
        "    return trajectory_df, particles_df"
      ],
      "metadata": {
        "id": "cPKMmH8QILLR"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trajectory_df, particles_df = load_data()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    # Plot true trajectory\n",
        "ax.plot(trajectory_df['true_x'], trajectory_df['true_y'],'r-', linewidth=3, label='True trajectory', alpha=0.8)\n",
        "\n",
        "    # Plot estimated trajectory\n",
        "ax.plot(trajectory_df['est_x'], trajectory_df['est_y'],'b--', linewidth=2, label='Estimated trajectory', alpha=0.8)\n",
        "\n",
        "    # Plot observations\n",
        "ax.scatter(trajectory_df['obs_x'], trajectory_df['obs_y'],c='green', s=30, alpha=0.6, label='Observations')\n",
        "\n",
        "    # Plot particle clouds at selected timesteps\n",
        "selected_timesteps = [0, 20, 40, 60, 80]\n",
        "colors = ['purple', 'orange', 'cyan', 'magenta', 'yellow']\n",
        "\n",
        "for i, timestep in enumerate(selected_timesteps):\n",
        "    if timestep in particles_df['timestep'].values:\n",
        "        particles_t = particles_df[particles_df['timestep'] == timestep]\n",
        "        ax.scatter(particles_t['x'], particles_t['y'],c=colors[i], s=10, alpha=0.3,label=f'Particles t={timestep*0.1:.1f}s')\n",
        "\n",
        "ax.set_xlabel('X position')\n",
        "ax.set_ylabel('Y position')\n",
        "ax.set_title('Particle Filter Tracking - Complete Trajectory')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('complete_trajectory.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PDe3f9NIIMT9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "a20cd672-cf79-4e76-e67b-63950be0b4e9"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'particles.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3777602911.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrajectory_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticles_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Plot true trajectory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1984702149.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Load particle data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mparticles_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'particles.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrajectory_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticles_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'particles.csv'"
          ]
        }
      ]
    }
  ]
}